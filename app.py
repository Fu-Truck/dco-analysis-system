import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from scipy import stats
from scipy.stats import norm
import warnings
import io
from datetime import datetime
import platform
import tempfile
import os
import sys
import subprocess

warnings.filterwarnings('ignore')

# ==================== é¡µé¢é…ç½® ====================
st.set_page_config(
    page_title="DCOç»¼åˆåˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== è‡ªå®šä¹‰CSSæ ·å¼ ====================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E3A8A;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.5rem;
        color: #2563EB;
        margin-top: 1.5rem;
        margin-bottom: 1rem;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #E5E7EB;
    }
    .section-header {
        font-size: 1.2rem;
        color: #374151;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
        font-weight: 600;
    }
    .stat-box {
        background-color: #F3F4F6;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #2563EB;
    }
    .warning-box {
        background-color: #FEF3C7;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #F59E0B;
    }
    .info-box {
        background-color: #E0F2FE;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #0EA5E9;
    }
    .success-box {
        background-color: #D1FAE5;
        border-radius: 10px;
        padding: 1rem;
        margin: 0.5rem 0;
        border-left: 4px solid #10B981;
    }
    .metric-card {
        background-color: white;
        border-radius: 10px;
        padding: 1rem;
        text-align: center;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border: 1px solid #E5E7EB;
    }
    .metric-value {
        font-size: 1.8rem;
        font-weight: bold;
        color: #1E3A8A;
    }
    .metric-label {
        font-size: 0.9rem;
        color: #6B7280;
    }
    .stButton > button {
        width: 100%;
        background-color: #2563EB;
        color: white;
        font-weight: bold;
        border: none;
        padding: 0.5rem;
        border-radius: 5px;
    }
    .stButton > button:hover {
        background-color: #1D4ED8;
    }
    .dataframe {
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)

# ==================== è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¢å¼ºç‰ˆï¼‰====================
def setup_chinese_font():
    """
    åœ¨Linuxç¯å¢ƒä¸­å®‰è£…å’Œè®¾ç½®ä¸­æ–‡å­—ä½“
    """
    system = platform.system()
    
    try:
        if system == "Windows":
            plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            return True
            
        elif system == "Darwin":  # macOS
            plt.rcParams['font.sans-serif'] = ['PingFang SC', 'STHeiti', 'Arial Unicode MS']
            plt.rcParams['axes.unicode_minus'] = False
            return True
            
        else:  # Linux (Streamlit Cloud)
            # å°è¯•å®‰è£…ä¸­æ–‡å­—ä½“
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å®‰è£…å­—ä½“
                import matplotlib.font_manager as fm
                
                # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
                chinese_fonts = ['WenQuanYi Zen Hei', 'Noto Sans CJK SC', 'Noto Sans SC', 
                                'Droid Sans Fallback', 'DejaVu Sans', 'Arial Unicode MS']
                
                for font in chinese_fonts:
                    try:
                        plt.rcParams['font.sans-serif'] = [font]
                        # æµ‹è¯•ä¸­æ–‡æ˜¾ç¤º
                        test_fig, test_ax = plt.subplots()
                        test_ax.set_title("æµ‹è¯•ä¸­æ–‡")
                        plt.close(test_fig)
                        plt.rcParams['axes.unicode_minus'] = False
                        return True
                    except:
                        continue
                
                # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡æ ‡ç­¾
                plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
                plt.rcParams['axes.unicode_minus'] = False
                return False
                
            except Exception as e:
                print(f"å­—ä½“è®¾ç½®å¤±è´¥: {e}")
                return False
                
    except Exception as e:
        print(f"å­—ä½“è®¾ç½®é”™è¯¯: {e}")
        return False

# åˆå§‹åŒ–å­—ä½“
FONT_CHINESE_SUPPORT = setup_chinese_font()

# ==================== è¾…åŠ©å‡½æ•°ï¼šå®‰å…¨çš„ä¸­æ–‡æ–‡æœ¬ ====================
def safe_text(text, default=None):
    """
    å¦‚æœä¸­æ–‡æ˜¾ç¤ºæœ‰é—®é¢˜ï¼Œè¿”å›è‹±æ–‡æˆ–é»˜è®¤æ–‡æœ¬
    """
    if FONT_CHINESE_SUPPORT:
        return text
    else:
        # ä¸­æ–‡åˆ°è‹±æ–‡çš„æ˜ å°„
        translations = {
            # æ‰¹æ¬¡åˆ†æç›¸å…³
            'AåŒº (çº¢è‰²: <50%ç›®æ ‡)': 'Zone A (<50% Target)',
            'BåŒº (é»„è‰²: 50%-80%ç›®æ ‡)': 'Zone B (50%-80% Target)',
            'CåŒº (ç»¿è‰²: 80%-120%ç›®æ ‡)': 'Zone C (80%-120% Target)',
            'å®é™…å€¼ (åˆ†é’Ÿ)': 'Actual Value (min)',
            'æ•´ä½“å‡å€¼': 'Mean',
            'æ•´ä½“ä¸­ä½æ•°': 'Median',
            'æ•´ä½“ä¼—æ•°': 'Mode',
            'ç›®æ ‡å‡å€¼': 'Target Mean',
            'UCL (ç›®æ ‡+20%)': 'UCL (+20%)',
            'LCL (ç›®æ ‡-20%)': 'LCL (-20%)',
            'UWL (ç›®æ ‡+50%)': 'UWL (+50%)',
            'LWL (ç›®æ ‡-50%)': 'LWL (-50%)',
            'USL (ä¸Šè§„æ ¼é™)': 'USL',
            'LSL (ä¸‹è§„æ ¼é™)': 'LSL',
            'å‰10%æ•°æ®': 'Top 10%',
            'å10%æ•°æ®': 'Bottom 10%',
            'æ•°æ®ç‚¹åºå·': 'Data Point',
            'æ—¶é—´ (åˆ†é’Ÿ)': 'Time (min)',
            'æ¦‚ç‡å¯†åº¦': 'Probability Density',
            'SPCæ§åˆ¶å›¾': 'SPC Control Chart',
            'è¿‡ç¨‹èƒ½åŠ›ä¸ç»Ÿè®¡åˆ†å¸ƒåˆ†æ': 'Process Capability & Distribution',
            
            # è§„åˆ™åç§°
            'è§„åˆ™1: ç‚¹è½åœ¨AåŒºä»¥å¤–': 'Rule 1: Point outside Zone A',
            'è§„åˆ™2: è¿ç»­9ä¸ªç‚¹åœ¨ç›®æ ‡çº¿åŒä¸€ä¾§': 'Rule 2: 9 points on same side',
            'è§„åˆ™3: è¿ç»­6ä¸ªç‚¹é€’å¢æˆ–é€’å‡': 'Rule 3: 6 points trend',
            'è§„åˆ™4: è¿ç»­14ä¸ªç‚¹ç›¸é‚»ç‚¹äº¤æ›¿ä¸Šä¸‹': 'Rule 4: 14 points alternating',
            
            # æ´»åŠ¨åˆ†æç›¸å…³
            'é˜¶æ®µ': 'Phase',
            'å¹³å‡è€—æ—¶': 'Avg Time',
            'æœ€å°è€—æ—¶': 'Min Time',
            'æœ€å¤§è€—æ—¶': 'Max Time',
            'æ ‡å‡†å·®': 'Std Dev',
            'æ´»åŠ¨æ•°': 'Activities',
            'è®°å½•æ•°': 'Records',
            'æ“ä½œå‘˜': 'Operator',
            'æ´»åŠ¨æè¿°': 'Activity',
            'æ‰¹æ¬¡å·': 'Batch ID',
            'æœ€å¿«è®°å½•': 'Fastest Record',
            'æœ€æ…¢è®°å½•': 'Slowest Record',
            
            # åˆ†ä½æ•°
            'å‰10%åˆ†ä½': '10th Percentile',
            'å10%åˆ†ä½': '90th Percentile',
            'å‰25%åˆ†ä½': '25th Percentile',
            'å75%åˆ†ä½': '75th Percentile',
        }
        
        if text in translations:
            return translations[text]
        elif default:
            return default
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ç¿»è¯‘ï¼Œå°è¯•ç§»é™¤ä¸­æ–‡
            import re
            english_only = re.sub(r'[^\x00-\x7F]+', '', text)
            return english_only if english_only else "Label"

# ==================== æ ‡é¢˜åŒºåŸŸ ====================
st.markdown('<h1 class="main-header">ğŸ“Š DCOç»¼åˆåˆ†æç³»ç»Ÿ</h1>', unsafe_allow_html=True)
st.markdown("---")

# æ˜¾ç¤ºå­—ä½“çŠ¶æ€
if not FONT_CHINESE_SUPPORT:
    st.warning("âš ï¸ å½“å‰ç¯å¢ƒä¸­æ–‡æ˜¾ç¤ºå¯èƒ½ä¸æ­£å¸¸ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ ‡ç­¾æ›¿ä»£")

# ==================== ä¾§è¾¹æ  ====================
with st.sidebar:
    st.markdown("## âš™ï¸ æ§åˆ¶é¢æ¿")
    st.markdown("---")
    
    # æ˜¾ç¤ºæç¤ºä¿¡æ¯
    st.info("ğŸ“Œ å½“å‰ç‰ˆæœ¬ï¼šå®Œæ•´ç»Ÿè®¡åˆ†æä¸SPCæ§åˆ¶")
    
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    st.markdown("### ğŸ“‚ æ•°æ®ä¸Šä¼ ")
    
    batch_file = st.file_uploader(
        "**æ‰¹æ¬¡æ•°æ®** (DCO-batch data.xlsx)",
        type=['xlsx', 'xls'],
        help="ä¸Šä¼ åŒ…å«æ‰¹æ¬¡ä¿¡æ¯çš„Excelæ–‡ä»¶"
    )
    
    activity_file = st.file_uploader(
        "**æ´»åŠ¨æ•°æ®** (DCO-activity data.xlsx)",
        type=['xlsx', 'xls'],
        help="ä¸Šä¼ åŒ…å«æ´»åŠ¨ä¿¡æ¯çš„Excelæ–‡ä»¶"
    )
    
    st.markdown("---")
    
    # åˆ†æè®¾ç½®
    st.markdown("### âš¡ åˆ†æè®¾ç½®")
    
    analysis_points = st.number_input(
        "SPCåˆ†ææ•°æ®ç‚¹æ•°",
        min_value=10,
        max_value=500,
        value=100,
        step=10,
        help="é€‰æ‹©ç”¨äºSPCåˆ†æçš„æœ€æ–°æ•°æ®ç‚¹æ•°é‡"
    )
    
    time_threshold = st.number_input(
        "Time Elapsedé˜ˆå€¼ (ç§’)",
        min_value=3600,
        max_value=36000,
        value=10800,
        step=600,
        help="åˆ é™¤Time Elapsedå¤§äºæ­¤å€¼çš„æ•°æ®"
    )
    
    show_details = st.checkbox(
        "æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯",
        value=True,
        help="å‹¾é€‰ä»¥æ˜¾ç¤ºè¯¦ç»†çš„ç»Ÿè®¡åˆ†æç»“æœ"
    )
    
    st.markdown("---")
    
    # æ‰§è¡ŒæŒ‰é’®
    run_button = st.button("ğŸš€ å¼€å§‹å…¨é¢åˆ†æ", type="primary", use_container_width=True)
    
    st.markdown("---")
    st.markdown("### ğŸ“Œ ä½¿ç”¨è¯´æ˜")
    st.info(
        "1. ä¸Šä¼ æ‰¹æ¬¡æ•°æ®å’Œæ´»åŠ¨æ•°æ®Excelæ–‡ä»¶\n"
        "2. è®¾ç½®åˆ†æå‚æ•°\n"
        "3. ç‚¹å‡»'å¼€å§‹å…¨é¢åˆ†æ'æŒ‰é’®\n"
        "4. ç³»ç»Ÿå°†æ‰§è¡Œï¼š\n"
        "   - æ‰¹æ¬¡æ•°æ®æ¸…æ´—\n"
        "   - SPCæ§åˆ¶å›¾åˆ†æï¼ˆå«å¼‚å¸¸ç‚¹æ ‡è®°ï¼‰\n"
        "   - å®Œæ•´ç»Ÿè®¡åˆ†æï¼ˆå‡å€¼ã€ä¸­ä½æ•°ã€ä¼—æ•°ã€åˆ†ä½æ•°ï¼‰\n"
        "   - æ­£æ€åˆ†å¸ƒæ‹Ÿåˆ\n"
        "   - æ´»åŠ¨æ•°æ®åˆ†æï¼ˆæœ€å¤§å€¼ã€æœ€å°å€¼ï¼‰"
    )

# ==================== æ‰¹æ¬¡æ•°æ®åˆ†æå‡½æ•° ====================
def analyze_batch_data(df, analysis_points=100, time_threshold=10800):
    """
    æ‰¹æ¬¡æ•°æ®åˆ†æï¼šæ•°æ®æ¸…æ´—ã€SPCåˆ†æã€å¼‚å¸¸æ£€æµ‹ã€å®Œæ•´ç»Ÿè®¡åˆ†æ
    """
    results = {
        'cleaning_steps': [],
        'statistics': {},
        'anomalies': None,
        'figures': {}
    }
    
    # ========== æ•°æ®æ¸…æ´— ==========
    original_rows = len(df)
    results['cleaning_steps'].append(f"åŸå§‹æ•°æ®è¡Œæ•°: {original_rows}")
    
    # 1. åˆ é™¤Process Order IDç©ºå€¼
    df = df.dropna(subset=['Process Order ID'])
    results['cleaning_steps'].append(f"åˆ é™¤Gåˆ—ç©ºå€¼åè¡Œæ•°: {len(df)}")
    
    # 2. åˆ é™¤é‡å¤å€¼
    df = df.drop_duplicates(subset=['Process Order ID'], keep='first')
    results['cleaning_steps'].append(f"åˆ é™¤Gåˆ—é‡å¤å€¼åè¡Œæ•°: {len(df)}")
    
    # 3. åˆ é™¤End date/timeç©ºå€¼
    df = df.dropna(subset=['End date/time'])
    results['cleaning_steps'].append(f"åˆ é™¤Kåˆ—ç©ºå€¼åè¡Œæ•°: {len(df)}")
    
    # 4. ä¿ç•™"å¹²æ¸…"ç±»å‹
    df = df[df['Type'] == 'å¹²æ¸…']
    results['cleaning_steps'].append(f"ä¿ç•™'å¹²æ¸…'ç±»å‹åè¡Œæ•°: {len(df)}")
    
    # 5. ä¿ç•™æŒ‡å®šäº§çº¿
    allowed_locations = ['CP Line 9', 'CP Line 10', 'CP Line 11', 'CP Line 12', 'CP Line 05', 'CP Line 08']
    df = df[df['Location'].isin(allowed_locations)]
    results['cleaning_steps'].append(f"ä¿ç•™æŒ‡å®šäº§çº¿åè¡Œæ•°: {len(df)}")
    
    # 6. åˆ é™¤Time Elapsedå¤§äºé˜ˆå€¼çš„æ•°æ®
    if 'Time Elapsed (seconds)' in df.columns:
        before_count = len(df)
        df = df[df['Time Elapsed (seconds)'] <= time_threshold]
        removed_count = before_count - len(df)
        results['cleaning_steps'].append(f"åˆ é™¤Time Elapsed > {time_threshold}çš„æ•°æ®åè¡Œæ•°: {len(df)} (åˆ é™¤äº†{removed_count}è¡Œ)")
    
    # 7. å°†ç§’è½¬æ¢ä¸ºåˆ†é’Ÿ
    columns_to_convert = ['Time Elapsed (seconds)', 'Planned Duration (seconds)', 
                          'Changeover Planned/Actual Difference (seconds)']
    
    for col in columns_to_convert:
        if col in df.columns:
            df[col] = (df[col] / 60).round(2)
            new_col_name = col.replace('(seconds)', '(minutes)')
            df.rename(columns={col: new_col_name}, inplace=True)
    
    results['cleaning_steps'].append(f"\næ¸…æ´—å®Œæˆï¼Œæœ€ç»ˆæ•°æ®è¡Œæ•°: {len(df)}")
    results['cleaning_steps'].append(f"å…±åˆ é™¤äº† {original_rows - len(df)} è¡Œæ•°æ®")
    
    # ========== SPCåˆ†æå‡†å¤‡ ==========
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    df['End date/time'] = pd.to_datetime(df['End date/time'])
    
    # æŒ‰æ—¥æœŸé™åºæ’åºï¼Œå–å‰Nä¸ªæ•°æ®ï¼Œå†æŒ‰æ—¶é—´å‡åºæ’åˆ—
    df_sorted = df.sort_values('End date/time', ascending=False).head(analysis_points)
    df_sorted = df_sorted.sort_values('End date/time', ascending=True)
    
    # è·å–æ•°æ®åˆ—
    data_column = 'Time Elapsed (minutes)'
    target_column = 'Planned Duration (minutes)'
    
    # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œå°è¯•æŸ¥æ‰¾æ›¿ä»£åˆ—
    if data_column not in df_sorted.columns:
        time_columns = [col for col in df_sorted.columns if 'Time Elapsed' in col]
        if time_columns:
            data_column = time_columns[0]
    
    if target_column not in df_sorted.columns:
        planned_columns = [col for col in df_sorted.columns if 'Planned' in col]
        if planned_columns:
            target_column = planned_columns[0]
    
    if data_column not in df_sorted.columns or target_column not in df_sorted.columns:
        st.error("æ— æ³•æ‰¾åˆ°å¿…è¦çš„æ•°æ®åˆ—")
        return None
    
    data_values = df_sorted[data_column].values
    target_values = df_sorted[target_column].values
    n_points = len(data_values)
    
    # ========== å®Œæ•´ç»Ÿè®¡è®¡ç®— ==========
    overall_mean = np.mean(data_values)
    overall_median = np.median(data_values)
    overall_std = np.std(data_values, ddof=1)
    
    # è®¡ç®—ä¼—æ•°
    overall_mode_result = stats.mode(data_values, keepdims=True)
    overall_mode = overall_mode_result.mode[0]
    overall_mode_count = overall_mode_result.count[0]
    
    # è®¡ç®—åˆ†ä½æ•°
    sorted_data = np.sort(data_values)
    front_10_percentile = np.percentile(sorted_data, 10)
    back_10_percentile = np.percentile(sorted_data, 90)
    front_25_percentile = np.percentile(sorted_data, 25)
    back_25_percentile = np.percentile(sorted_data, 75)
    
    # è®¡ç®—æœ€å¤§å€¼å’Œæœ€å°å€¼
    min_value = np.min(data_values)
    max_value = np.max(data_values)
    range_value = max_value - min_value
    
    # ç›®æ ‡å€¼ç»Ÿè®¡
    target_mean = np.mean(target_values)
    
    # æ§åˆ¶çº¿å’Œè­¦æˆ’çº¿
    ucl = target_mean * 1.2
    lcl = max(0, target_mean * 0.8)
    uwl = target_mean * 1.5
    lwl = max(0, target_mean * 0.5)
    
    # åŒºåŸŸåˆ’åˆ†
    green_lower = target_mean * 0.8
    green_upper = target_mean * 1.2
    yellow_upper_lower = target_mean * 1.2
    yellow_upper_upper = target_mean * 1.5
    yellow_lower_lower = target_mean * 0.5
    yellow_lower_upper = target_mean * 0.8
    red_upper_lower = target_mean * 1.5
    red_upper_upper = max(target_mean * 3, 300)
    red_lower_lower = 0
    red_lower_upper = target_mean * 0.5
    
    # è§„æ ¼é™
    usl = target_mean * 1.2
    lsl = target_mean * 0.8
    
    # è¿‡ç¨‹èƒ½åŠ›æŒ‡æ•°
    cpu = (usl - overall_mean) / (3 * overall_std) if overall_std > 0 else 0
    cpl = (overall_mean - lsl) / (3 * overall_std) if overall_std > 0 else 0
    cpk = min(cpu, cpl)
    
    std_total = np.std(data_values, ddof=0)
    ppu = (usl - overall_mean) / (3 * std_total) if std_total > 0 else 0
    ppl = (overall_mean - lsl) / (3 * std_total) if std_total > 0 else 0
    ppk = min(ppu, ppl)
    
    cp = (usl - lsl) / (6 * overall_std) if overall_std > 0 else 0
    
    # ä¿å­˜ç»Ÿè®¡ç»“æœ
    results['statistics'] = {
        'n_points': n_points,
        'overall_mean': overall_mean,
        'overall_median': overall_median,
        'overall_std': overall_std,
        'overall_mode': overall_mode,
        'overall_mode_count': overall_mode_count,
        'front_10_percentile': front_10_percentile,
        'back_10_percentile': back_10_percentile,
        'front_25_percentile': front_25_percentile,
        'back_25_percentile': back_25_percentile,
        'min_value': min_value,
        'max_value': max_value,
        'range_value': range_value,
        'target_mean': target_mean,
        'ucl': ucl,
        'lcl': lcl,
        'uwl': uwl,
        'lwl': lwl,
        'green_lower': green_lower,
        'green_upper': green_upper,
        'yellow_upper_lower': yellow_upper_lower,
        'yellow_upper_upper': yellow_upper_upper,
        'yellow_lower_lower': yellow_lower_lower,
        'yellow_lower_upper': yellow_lower_upper,
        'red_upper_lower': red_upper_lower,
        'red_upper_upper': red_upper_upper,
        'red_lower_lower': red_lower_lower,
        'red_lower_upper': red_lower_upper,
        'usl': usl,
        'lsl': lsl,
        'cp': cp,
        'cpk': cpk,
        'ppk': ppk
    }
    
    # ========== åˆ›å»ºSPCå›¾ï¼ˆä½¿ç”¨å®‰å…¨æ–‡æœ¬ï¼‰==========
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12), gridspec_kw={'height_ratios': [3, 1]})
    
    x_values = range(len(data_values))
    n_front_10 = max(1, int(n_points * 0.1))
    n_back_10 = max(1, int(n_points * 0.1))
    
    # ä¸Šéƒ¨ï¼šSPCæ§åˆ¶å›¾ - ä½¿ç”¨ safe_text ç¡®ä¿æ ‡ç­¾æ­£ç¡®æ˜¾ç¤º
    ax1.axhspan(red_lower_lower, red_lower_upper, alpha=0.2, color='red', 
                label=safe_text('AåŒº (çº¢è‰²: <50%ç›®æ ‡)', 'Zone A (<50%)'))
    ax1.axhspan(yellow_lower_lower, yellow_lower_upper, alpha=0.2, color='yellow', 
                label=safe_text('BåŒº (é»„è‰²: 50%-80%ç›®æ ‡)', 'Zone B (50%-80%)'))
    ax1.axhspan(green_lower, green_upper, alpha=0.2, color='green', 
                label=safe_text('CåŒº (ç»¿è‰²: 80%-120%ç›®æ ‡)', 'Zone C (80%-120%)'))
    ax1.axhspan(yellow_upper_lower, yellow_upper_upper, alpha=0.2, color='yellow')
    ax1.axhspan(red_upper_lower, red_upper_upper, alpha=0.2, color='red')
    
    # ç»˜åˆ¶æ•°æ®ç‚¹
    ax1.plot(x_values, data_values, 'o-', color='blue', markersize=4, 
             label=safe_text('å®é™…å€¼ (åˆ†é’Ÿ)', 'Actual (min)'))
    
    # ç»˜åˆ¶ç»Ÿè®¡çº¿ - ä½¿ç”¨ f-string ä½†ç¡®ä¿ä¸­æ–‡éƒ¨åˆ†è¢«è½¬æ¢
    mean_label = f"{safe_text('æ•´ä½“å‡å€¼', 'Mean')}: {overall_mean:.2f}"
    median_label = f"{safe_text('æ•´ä½“ä¸­ä½æ•°', 'Median')}: {overall_median:.2f}"
    mode_label = f"{safe_text('æ•´ä½“ä¼—æ•°', 'Mode')}: {overall_mode:.2f}"
    target_label = f"{safe_text('ç›®æ ‡å‡å€¼', 'Target')}: {target_mean:.2f}"
    ucl_label = f"{safe_text('UCL', 'UCL')}: {ucl:.2f}"
    lcl_label = f"{safe_text('LCL', 'LCL')}: {lcl:.2f}"
    uwl_label = f"{safe_text('UWL', 'UWL')}: {uwl:.2f}"
    lwl_label = f"{safe_text('LWL', 'LWL')}: {lwl:.2f}"
    usl_label = f"{safe_text('USL', 'USL')}: {usl:.2f}"
    lsl_label = f"{safe_text('LSL', 'LSL')}: {lsl:.2f}"
    
    ax1.axhline(y=overall_mean, color='darkblue', linestyle='--', linewidth=1.5, alpha=0.7, label=mean_label)
    ax1.axhline(y=overall_median, color='darkgreen', linestyle='--', linewidth=1.5, alpha=0.7, label=median_label)
    ax1.axhline(y=overall_mode, color='darkorange', linestyle='--', linewidth=1.5, alpha=0.7, label=mode_label)
    ax1.axhline(y=target_mean, color='purple', linestyle='-.', linewidth=2, label=target_label)
    ax1.axhline(y=ucl, color='red', linestyle='--', linewidth=2, label=ucl_label)
    ax1.axhline(y=lcl, color='red', linestyle='--', linewidth=2, label=lcl_label)
    ax1.axhline(y=uwl, color='orange', linestyle=':', linewidth=2, label=uwl_label)
    ax1.axhline(y=lwl, color='orange', linestyle=':', linewidth=2, label=lwl_label)
    ax1.axhline(y=usl, color='darkred', linestyle='-', linewidth=1.5, label=usl_label)
    ax1.axhline(y=lsl, color='darkred', linestyle='-', linewidth=1.5, label=lsl_label)
    
    # æ ‡è®°å‰å10%åŒºåŸŸ
    front_label = f"{safe_text('å‰10%æ•°æ®', 'Top 10%')} (1-{n_front_10})"
    back_label = f"{safe_text('å10%æ•°æ®', 'Bottom 10%')} ({n_points - n_back_10 + 1}-{n_points})"
    ax1.axvspan(0, n_front_10-1, alpha=0.1, color='lightblue', label=front_label)
    ax1.axvspan(n_points - n_back_10, n_points-1, alpha=0.1, color='lightcoral', label=back_label)
    
    # ========== å¼‚å¸¸ç‚¹æ£€æµ‹å’Œæ ‡è®° ==========
    anomaly_records = []
    rule1_indices = []
    rule2_indices = []
    rule3_indices = []
    rule4_indices = []
    
    # è§„åˆ™1: ä¸€ä¸ªç‚¹è½åœ¨AåŒºä»¥å¤–ï¼ˆè¶…å‡ºUCL/LCLï¼‰
    for i, value in enumerate(data_values):
        if value > ucl or value < lcl:
            rule = safe_text('è§„åˆ™1: ç‚¹è½åœ¨AåŒºä»¥å¤–', 'Rule 1: Outside Zone A')
            location = df_sorted.iloc[i]['Location'] if 'Location' in df_sorted.columns else 'Unknown'
            process_id = df_sorted.iloc[i]['Process Order ID'] if 'Process Order ID' in df_sorted.columns else 'Unknown'
            date_time = df_sorted.iloc[i]['End date/time'] if 'End date/time' in df_sorted.columns else 'Unknown'
            anomaly_records.append({
                'åºå·': i+1,
                'äº§çº¿': location,
                'æ‰¹æ¬¡å·': process_id,
                'æ—¶é—´': date_time,
                'å®é™…å€¼': round(value, 2),
                'ç›®æ ‡å€¼': round(target_values[i], 2),
                'åå·®': round(value - target_values[i], 2),
                'å¼‚å¸¸è§„åˆ™': rule
            })
            rule1_indices.append(i)
            # åœ¨å›¾ä¸Šæ ‡è®°å¼‚å¸¸ç‚¹ï¼ˆçº¢è‰²åœ†åœˆï¼‰
            ax1.plot(i, value, 'ro', markersize=10, markeredgecolor='black', markeredgewidth=1.5, 
                    label=safe_text('è§„åˆ™1å¼‚å¸¸ç‚¹', 'Rule 1') if i == rule1_indices[0] else "")
    
    # è§„åˆ™2: è¿ç»­9ä¸ªç‚¹è½åœ¨ä¸­å¿ƒçº¿çš„åŒä¸€ä¾§
    def check_consecutive_on_one_side(data, target, n=9):
        anomalies = []
        for i in range(len(data) - n + 1):
            segment = data[i:i+n]
            if all(x > target for x in segment):
                for j in range(i, i+n):
                    anomalies.append(j)
            elif all(x < target for x in segment):
                for j in range(i, i+n):
                    anomalies.append(j)
        return list(set(anomalies))
    
    rule2_anomalies = check_consecutive_on_one_side(data_values, target_mean, 9)
    for idx in rule2_anomalies:
        if idx not in [a['åºå·']-1 for a in anomaly_records]:
            rule = safe_text('è§„åˆ™2: è¿ç»­9ä¸ªç‚¹åœ¨ç›®æ ‡çº¿åŒä¸€ä¾§', 'Rule 2: 9 points same side')
            location = df_sorted.iloc[idx]['Location'] if 'Location' in df_sorted.columns else 'Unknown'
            process_id = df_sorted.iloc[idx]['Process Order ID'] if 'Process Order ID' in df_sorted.columns else 'Unknown'
            date_time = df_sorted.iloc[idx]['End date/time'] if 'End date/time' in df_sorted.columns else 'Unknown'
            anomaly_records.append({
                'åºå·': idx+1,
                'äº§çº¿': location,
                'æ‰¹æ¬¡å·': process_id,
                'æ—¶é—´': date_time,
                'å®é™…å€¼': round(data_values[idx], 2),
                'ç›®æ ‡å€¼': round(target_values[idx], 2),
                'åå·®': round(data_values[idx] - target_values[idx], 2),
                'å¼‚å¸¸è§„åˆ™': rule
            })
            rule2_indices.append(idx)
            ax1.plot(idx, data_values[idx], 'yo', markersize=10, markeredgecolor='black', markeredgewidth=1.5,
                    label=safe_text('è§„åˆ™2å¼‚å¸¸ç‚¹', 'Rule 2') if idx == rule2_anomalies[0] else "")
    
    # è§„åˆ™3: è¿ç»­6ä¸ªç‚¹é€’å¢æˆ–é€’å‡
    def check_trend(data, n=6):
        anomalies = []
        for i in range(len(data) - n + 1):
            segment = data[i:i+n]
            if all(segment[j] < segment[j+1] for j in range(n-1)):
                for j in range(i, i+n):
                    anomalies.append(j)
            elif all(segment[j] > segment[j+1] for j in range(n-1)):
                for j in range(i, i+n):
                    anomalies.append(j)
        return list(set(anomalies))
    
    rule3_anomalies = check_trend(data_values, 6)
    for idx in rule3_anomalies:
        if idx not in [a['åºå·']-1 for a in anomaly_records]:
            rule = safe_text('è§„åˆ™3: è¿ç»­6ä¸ªç‚¹é€’å¢æˆ–é€’å‡', 'Rule 3: 6 points trend')
            location = df_sorted.iloc[idx]['Location'] if 'Location' in df_sorted.columns else 'Unknown'
            process_id = df_sorted.iloc[idx]['Process Order ID'] if 'Process Order ID' in df_sorted.columns else 'Unknown'
            date_time = df_sorted.iloc[idx]['End date/time'] if 'End date/time' in df_sorted.columns else 'Unknown'
            anomaly_records.append({
                'åºå·': idx+1,
                'äº§çº¿': location,
                'æ‰¹æ¬¡å·': process_id,
                'æ—¶é—´': date_time,
                'å®é™…å€¼': round(data_values[idx], 2),
                'ç›®æ ‡å€¼': round(target_values[idx], 2),
                'åå·®': round(data_values[idx] - target_values[idx], 2),
                'å¼‚å¸¸è§„åˆ™': rule
            })
            rule3_indices.append(idx)
            ax1.plot(idx, data_values[idx], 'go', markersize=10, markeredgecolor='black', markeredgewidth=1.5,
                    label=safe_text('è§„åˆ™3å¼‚å¸¸ç‚¹', 'Rule 3') if idx == rule3_anomalies[0] else "")
    
    # è§„åˆ™4: è¿ç»­14ä¸ªç‚¹ä¸­ç›¸é‚»ç‚¹äº¤æ›¿ä¸Šä¸‹
    def check_alternating(data, n=14):
        anomalies = []
        for i in range(len(data) - n + 1):
            segment = data[i:i+n]
            is_alternating = True
            for j in range(n-1):
                if j % 2 == 0:
                    if not (segment[j] < segment[j+1]):
                        is_alternating = False
                        break
                else:
                    if not (segment[j] > segment[j+1]):
                        is_alternating = False
                        break
            if is_alternating:
                for j in range(i, i+n):
                    anomalies.append(j)
        return list(set(anomalies))
    
    rule4_anomalies = check_alternating(data_values, 14)
    for idx in rule4_anomalies:
        if idx not in [a['åºå·']-1 for a in anomaly_records]:
            rule = safe_text('è§„åˆ™4: è¿ç»­14ä¸ªç‚¹ç›¸é‚»ç‚¹äº¤æ›¿ä¸Šä¸‹', 'Rule 4: 14 points alternating')
            location = df_sorted.iloc[idx]['Location'] if 'Location' in df_sorted.columns else 'Unknown'
            process_id = df_sorted.iloc[idx]['Process Order ID'] if 'Process Order ID' in df_sorted.columns else 'Unknown'
            date_time = df_sorted.iloc[idx]['End date/time'] if 'End date/time' in df_sorted.columns else 'Unknown'
            anomaly_records.append({
                'åºå·': idx+1,
                'äº§çº¿': location,
                'æ‰¹æ¬¡å·': process_id,
                'æ—¶é—´': date_time,
                'å®é™…å€¼': round(data_values[idx], 2),
                'ç›®æ ‡å€¼': round(target_values[idx], 2),
                'åå·®': round(data_values[idx] - target_values[idx], 2),
                'å¼‚å¸¸è§„åˆ™': rule
            })
            rule4_indices.append(idx)
            ax1.plot(idx, data_values[idx], 'mo', markersize=10, markeredgecolor='black', markeredgewidth=1.5,
                    label=safe_text('è§„åˆ™4å¼‚å¸¸ç‚¹', 'Rule 4') if idx == rule4_anomalies[0] else "")
    
    # è®¾ç½®å›¾è¡¨å±æ€§
    ax1.set_ylim(bottom=0, top=min(300, max(data_values) * 1.2))
    ax1.set_xlabel(safe_text('æ•°æ®ç‚¹åºå· (æŒ‰æ—¶é—´æ’åº)', 'Data Point (Chronological)'), fontsize=12)
    ax1.set_ylabel(safe_text('æ—¶é—´ (åˆ†é’Ÿ)', 'Time (min)'), fontsize=12)
    ax1.set_title(safe_text('SPCæ§åˆ¶å›¾ - åŸºäºç›®æ ‡å€¼ç™¾åˆ†æ¯”çš„æ§åˆ¶é™', 'SPC Chart - Target Based Control Limits'), 
                 fontsize=14, fontweight='bold')
    
    # å¤„ç†å›¾ä¾‹é‡å¤é—®é¢˜
    handles, labels = ax1.get_legend_handles_labels()
    by_label = dict(zip(labels, handles))
    ax1.legend(by_label.values(), by_label.keys(), loc='upper right', fontsize=8, ncol=2)
    
    ax1.grid(True, alpha=0.3)
    
    # è®¾ç½®xè½´æ ‡ç­¾
    if len(x_values) <= 20:
        xtick_labels = [d.strftime('%m-%d %H:%M') for d in df_sorted['End date/time']]
        ax1.set_xticks(x_values)
        ax1.set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=8)
    else:
        step = len(x_values) // 10
        xtick_positions = x_values[::step]
        xtick_labels = [df_sorted['End date/time'].iloc[i].strftime('%m-%d %H:%M') for i in xtick_positions]
        ax1.set_xticks(xtick_positions)
        ax1.set_xticklabels(xtick_labels, rotation=45, ha='right', fontsize=8)
    
    # ä¸‹éƒ¨ï¼šè¿‡ç¨‹èƒ½åŠ›åˆ†æå›¾è¡¨
    ax2.hist(data_values, bins=20, density=True, alpha=0.7, color='skyblue', edgecolor='black', 
             label=safe_text('å®é™…å€¼åˆ†å¸ƒ', 'Actual Distribution'))
    x_norm = np.linspace(max(0, min(data_values)), max(data_values), 100)
    y_norm = norm.pdf(x_norm, overall_mean, std_total)
    ax2.plot(x_norm, y_norm, 'r-', linewidth=2, label=safe_text('æ­£æ€åˆ†å¸ƒæ‹Ÿåˆ', 'Normal Fit'))
    
    # æ ‡è®°è§„æ ¼é™å’Œç»Ÿè®¡é‡
    ax2.axvline(x=usl, color='darkred', linestyle='--', linewidth=2, label=f"USL: {usl:.2f}")
    ax2.axvline(x=lsl, color='darkred', linestyle='--', linewidth=2, label=f"LSL: {lsl:.2f}")
    ax2.axvline(x=target_mean, color='purple', linestyle='-.', linewidth=2, 
                label=f"{safe_text('ç›®æ ‡', 'Target')}: {target_mean:.2f}")
    ax2.axvline(x=overall_mean, color='black', linestyle='-', linewidth=2, 
                label=f"{safe_text('å‡å€¼', 'Mean')}: {overall_mean:.2f}")
    ax2.axvline(x=overall_median, color='darkgreen', linestyle='--', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('ä¸­ä½æ•°', 'Median')}: {overall_median:.2f}")
    ax2.axvline(x=overall_mode, color='darkorange', linestyle='--', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('ä¼—æ•°', 'Mode')}: {overall_mode:.2f}")
    
    # æ ‡è®°åˆ†ä½ç‚¹
    ax2.axvline(x=front_10_percentile, color='blue', linestyle=':', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('å‰10%åˆ†ä½', '10th Pctl')}: {front_10_percentile:.2f}")
    ax2.axvline(x=back_10_percentile, color='red', linestyle=':', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('å10%åˆ†ä½', '90th Pctl')}: {back_10_percentile:.2f}")
    ax2.axvline(x=front_25_percentile, color='lightblue', linestyle=':', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('å‰25%åˆ†ä½', '25th Pctl')}: {front_25_percentile:.2f}")
    ax2.axvline(x=back_25_percentile, color='lightcoral', linestyle=':', linewidth=1.5, alpha=0.7, 
                label=f"{safe_text('å75%åˆ†ä½', '75th Pctl')}: {back_25_percentile:.2f}")
    
    ax2.set_xlim(left=0, right=min(300, max(data_values) * 1.2))
    ax2.set_xlabel(safe_text('æ—¶é—´ (åˆ†é’Ÿ)', 'Time (min)'), fontsize=12)
    ax2.set_ylabel(safe_text('æ¦‚ç‡å¯†åº¦', 'Probability Density'), fontsize=12)
    ax2.set_title(safe_text('è¿‡ç¨‹èƒ½åŠ›ä¸ç»Ÿè®¡åˆ†å¸ƒåˆ†æ', 'Process Capability & Distribution'), 
                 fontsize=14, fontweight='bold')
    ax2.legend(loc='upper left', fontsize=8)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    results['figures']['spc_chart'] = fig
    
    # åˆ›å»ºå¼‚å¸¸ç‚¹DataFrameå¹¶å»é‡
    if anomaly_records:
        anomaly_df = pd.DataFrame(anomaly_records)
        anomaly_df = anomaly_df.drop_duplicates(subset=['æ‰¹æ¬¡å·', 'æ—¶é—´'])
        anomaly_df = anomaly_df.sort_values('åºå·')
        results['anomalies'] = anomaly_df
    
    return results

# ==================== æ´»åŠ¨æ•°æ®åˆ†æå‡½æ•° ====================
def analyze_activity_data(df):
    """
    æ´»åŠ¨æ•°æ®åˆ†æï¼šæ•°æ®æ¸…æ´—ã€é˜¶æ®µåˆ†æï¼ˆæœ€å¤§å€¼ã€æœ€å°å€¼åˆ†æï¼‰
    """
    results = {
        'cleaning_steps': [],
        'phase_analysis': {},
        'figures': {}
    }
    
    # ========== æ•°æ®æ¸…æ´— ==========
    original_rows = len(df)
    results['cleaning_steps'].append(f"åŸå§‹æ•°æ®è¡Œæ•°: {original_rows}")
    
    # ç­›é€‰æŒ‡å®šäº§çº¿
    area_list = ['CPLine 9', 'CP Line 10', 'CP Line 11', 'CP Line 12', 'CP Line 05', 'CP Line08']
    df = df[df['Area'].isin(area_list)]
    results['cleaning_steps'].append(f"ç­›é€‰æŒ‡å®šäº§çº¿åè¡Œæ•°: {len(df)}")
    
    # ç­›é€‰"å¹²æ¸…"ç±»å‹
    df = df[df['Changeover Type'] == 'å¹²æ¸…']
    results['cleaning_steps'].append(f"ç­›é€‰'å¹²æ¸…'ç±»å‹åè¡Œæ•°: {len(df)}")
    
    # åˆ é™¤Actual Durationç©ºå€¼
    original_count = len(df)
    df = df.dropna(subset=['Actual Duration (seconds)'])
    removed_count = original_count - len(df)
    results['cleaning_steps'].append(f"åˆ é™¤Actual Durationç©ºå€¼{removed_count}è¡Œï¼Œå‰©ä½™è¡Œæ•°ï¼š{len(df)}")
    
    # å°†ç§’æ•°æ®è½¬æ¢ä¸ºåˆ†é’Ÿ
    if 'Actual Duration (seconds)' in df.columns:
        df['Actual Duration (minutes)'] = (df['Actual Duration (seconds)'] / 60).round(2)
    
    results['cleaning_steps'].append(f"\næ¸…æ´—å®Œæˆï¼Œæœ€ç»ˆæ•°æ®è¡Œæ•°: {len(df)}")
    
    # è®¡ç®—æ‰¹æ¬¡ä¿¡æ¯
    if 'PO Number' in df.columns:
        total_batches = df['PO Number'].nunique()
        results['batch_info'] = {
            'total_batches': total_batches,
            'total_records': len(df)
        }
        
        if 'Created At' in df.columns:
            df['Created At'] = pd.to_datetime(df['Created At'])
            results['batch_info']['time_range'] = f"{df['Created At'].min()} è‡³ {df['Created At'].max()}"
    
    # ========== é˜¶æ®µè¯¦ç»†åˆ†æ ==========
    phases = ['æ¸…åœºå‰å‡†å¤‡', 'æ¸…åœº', 'åˆ‡æ¢', 'äº§çº¿é…ç½®']
    
    for phase in phases:
        phase_data = df[df['Phase Name'] == phase]
        
        if len(phase_data) == 0:
            continue
        
        # åŸºç¡€ç»Ÿè®¡
        avg_duration = phase_data['Actual Duration (minutes)'].mean()
        min_duration = phase_data['Actual Duration (minutes)'].min()
        max_duration = phase_data['Actual Duration (minutes)'].max()
        std_duration = phase_data['Actual Duration (minutes)'].std()
        
        # æŒ‰æ´»åŠ¨æè¿°åˆ†ç»„
        activity_duration = phase_data.groupby('Task Description')['Actual Duration (minutes)'].agg(['mean', 'min', 'max', 'count']).round(2)
        activity_duration = activity_duration.sort_values('mean', ascending=False)
        
        # æŒ‰æ‰§è¡Œäººå‘˜åˆ†ç»„
        if 'Operator' in phase_data.columns:
            operator_duration = phase_data.groupby('Operator')['Actual Duration (minutes)'].agg(['mean', 'min', 'max', 'count']).round(2)
            operator_duration = operator_duration.sort_values('mean')
        else:
            operator_duration = pd.DataFrame()
        
        # æ‰¾å‡ºæœ€å¿«çš„å’Œæœ€æ…¢çš„è®°å½•
        fastest_record = phase_data.loc[phase_data['Actual Duration (minutes)'].idxmin()] if len(phase_data) > 0 else None
        slowest_record = phase_data.loc[phase_data['Actual Duration (minutes)'].idxmax()] if len(phase_data) > 0 else None
        
        fastest_info = {}
        slowest_info = {}
        
        if fastest_record is not None:
            fastest_info = {
                'æ—¶é—´': fastest_record.get('Actual Duration (minutes)', 'N/A'),
                'æ“ä½œå‘˜': fastest_record.get('Operator', 'N/A'),
                'æ´»åŠ¨æè¿°': fastest_record.get('Task Description', 'N/A'),
                'æ‰¹æ¬¡å·': fastest_record.get('PO Number', 'N/A')
            }
        
        if slowest_record is not None:
            slowest_info = {
                'æ—¶é—´': slowest_record.get('Actual Duration (minutes)', 'N/A'),
                'æ“ä½œå‘˜': slowest_record.get('Operator', 'N/A'),
                'æ´»åŠ¨æè¿°': slowest_record.get('Task Description', 'N/A'),
                'æ‰¹æ¬¡å·': slowest_record.get('PO Number', 'N/A')
            }
        
        results['phase_analysis'][phase] = {
            'å¹³å‡è€—æ—¶': avg_duration,
            'æœ€å°è€—æ—¶': min_duration,
            'æœ€å¤§è€—æ—¶': max_duration,
            'æ ‡å‡†å·®': std_duration,
            'æ´»åŠ¨æ•°é‡': len(activity_duration),
            'è®°å½•æ•°é‡': len(phase_data),
            'æœ€è€—æ—¶æ´»åŠ¨': activity_duration.head(5) if len(activity_duration) > 0 else pd.DataFrame(),
            'æ•ˆç‡æœ€é«˜äººå‘˜': operator_duration.head(5) if len(operator_duration) > 0 else pd.DataFrame(),
            'æœ€å¿«è®°å½•': fastest_info,
            'æœ€æ…¢è®°å½•': slowest_info
        }
    
    return results

# ==================== ä¸»ç¨‹åº ====================
if run_button:
    if batch_file is None or activity_file is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ‰¹æ¬¡æ•°æ®å’Œæ´»åŠ¨æ•°æ®æ–‡ä»¶ï¼")
    else:
        # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            # ========== ç¬¬ä¸€éƒ¨åˆ†ï¼šæ‰¹æ¬¡æ•°æ®åˆ†æ ==========
            status_text.text("ğŸ“Š æ­£åœ¨åˆ†ææ‰¹æ¬¡æ•°æ®...")
            progress_bar.progress(20)
            
            # è¯»å–æ‰¹æ¬¡æ•°æ®
            batch_df = pd.read_excel(batch_file)
            
            # æ‰§è¡Œæ‰¹æ¬¡æ•°æ®åˆ†æ
            with st.spinner("æ­£åœ¨æ‰§è¡Œæ‰¹æ¬¡æ•°æ®åˆ†æ..."):
                batch_results = analyze_batch_data(batch_df, analysis_points, time_threshold)
            
            if batch_results:
                # æ˜¾ç¤ºæ‰¹æ¬¡åˆ†æç»“æœ
                st.markdown('<h2 class="sub-header">ğŸ“ˆ æ‰¹æ¬¡æ•°æ®åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
                
                # åˆ›å»ºé€‰é¡¹å¡
                batch_tab1, batch_tab2, batch_tab3, batch_tab4 = st.tabs(
                    [safe_text("æ•°æ®æ¸…æ´—", "Data Cleaning"), 
                     safe_text("SPCæ§åˆ¶å›¾", "SPC Chart"), 
                     safe_text("å®Œæ•´ç»Ÿè®¡åˆ†æ", "Statistics"), 
                     safe_text("å¼‚å¸¸ç‚¹æ£€æµ‹", "Anomalies")]
                )
                
                with batch_tab1:
                    st.markdown(f"### {safe_text('æ•°æ®æ¸…æ´—æ­¥éª¤', 'Cleaning Steps')}")
                    for step in batch_results['cleaning_steps']:
                        st.write(f"- {step}")
                
                with batch_tab2:
                    if 'spc_chart' in batch_results['figures']:
                        st.pyplot(batch_results['figures']['spc_chart'])
                        
                        # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡æ‘˜è¦
                        if show_details:
                            st.markdown(f"### {safe_text('åŸºæœ¬ç»Ÿè®¡æ‘˜è¦', 'Basic Statistics')}")
                            stats = batch_results['statistics']
                            
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric(safe_text("å‡å€¼", "Mean"), f"{stats['overall_mean']:.2f}min")
                                st.metric(safe_text("ä¸­ä½æ•°", "Median"), f"{stats['overall_median']:.2f}min")
                            with col2:
                                st.metric(safe_text("æ ‡å‡†å·®", "Std Dev"), f"{stats['overall_std']:.2f}")
                                st.metric(safe_text("ä¼—æ•°", "Mode"), f"{stats['overall_mode']:.2f}")
                            with col3:
                                st.metric(safe_text("æœ€å°å€¼", "Min"), f"{stats['min_value']:.2f}min")
                                st.metric(safe_text("æœ€å¤§å€¼", "Max"), f"{stats['max_value']:.2f}min")
                            with col4:
                                st.metric(safe_text("æå·®", "Range"), f"{stats['range_value']:.2f}min")
                                st.metric("CPK", f"{stats['cpk']:.3f}")
                
                with batch_tab3:
                    st.markdown(f"### {safe_text('å®Œæ•´ç»Ÿè®¡åˆ†æ', 'Complete Statistics')}")
                    stats = batch_results['statistics']
                    
                    # æ•´ä½“ç»Ÿè®¡
                    st.markdown(f"#### {safe_text('æ•´ä½“ç»Ÿè®¡', 'Overall Statistics')}")
                    col_a1, col_a2, col_a3, col_a4 = st.columns(4)
                    with col_a1:
                        st.info(f"**{safe_text('å‡å€¼', 'Mean')}**: {stats['overall_mean']:.2f}min")
                    with col_a2:
                        st.info(f"**{safe_text('ä¸­ä½æ•°', 'Median')}**: {stats['overall_median']:.2f}min")
                    with col_a3:
                        st.info(f"**{safe_text('ä¼—æ•°', 'Mode')}**: {stats['overall_mode']:.2f}min ({stats['overall_mode_count']}æ¬¡)")
                    with col_a4:
                        st.info(f"**{safe_text('æ ‡å‡†å·®', 'Std Dev')}**: {stats['overall_std']:.2f}")
                    
                    # åˆ†ä½æ•°åˆ†æ
                    st.markdown(f"#### {safe_text('åˆ†ä½æ•°åˆ†æ', 'Percentile Analysis')}")
                    col_b1, col_b2, col_b3, col_b4 = st.columns(4)
                    with col_b1:
                        st.success(f"**{safe_text('å‰10%åˆ†ä½', '10th Pctl')}**: {stats['front_10_percentile']:.2f}min")
                    with col_b2:
                        st.success(f"**{safe_text('å10%åˆ†ä½', '90th Pctl')}**: {stats['back_10_percentile']:.2f}min")
                    with col_b3:
                        st.success(f"**{safe_text('å‰25%åˆ†ä½', '25th Pctl')}**: {stats['front_25_percentile']:.2f}min")
                    with col_b4:
                        st.success(f"**{safe_text('å75%åˆ†ä½', '75th Pctl')}**: {stats['back_25_percentile']:.2f}min")
                    
                    # æå€¼åˆ†æ
                    st.markdown(f"#### {safe_text('æå€¼åˆ†æ', 'Extreme Values')}")
                    col_c1, col_c2, col_c3 = st.columns(3)
                    with col_c1:
                        st.warning(f"**{safe_text('æœ€å°å€¼', 'Min')}**: {stats['min_value']:.2f}min")
                    with col_c2:
                        st.warning(f"**{safe_text('æœ€å¤§å€¼', 'Max')}**: {stats['max_value']:.2f}min")
                    with col_c3:
                        st.warning(f"**{safe_text('æå·®', 'Range')}**: {stats['range_value']:.2f}min")
                    
                    # è¿‡ç¨‹èƒ½åŠ›
                    st.markdown(f"#### {safe_text('è¿‡ç¨‹èƒ½åŠ›åˆ†æ', 'Process Capability')}")
                    col_d1, col_d2, col_d3 = st.columns(3)
                    with col_d1:
                        st.metric("CP", f"{stats['cp']:.3f}")
                    with col_d2:
                        st.metric("CPK", f"{stats['cpk']:.3f}")
                    with col_d3:
                        st.metric("PPK", f"{stats['ppk']:.3f}")
                    
                    # è¿‡ç¨‹èƒ½åŠ›è¯„ä¼°
                    cpk = stats['cpk']
                    if cpk >= 1.33:
                        st.success(f"âœ… **{safe_text('è¿‡ç¨‹èƒ½åŠ›å……è¶³', 'Capable')}** - {safe_text('è¿‡ç¨‹æ»¡è¶³è§„æ ¼è¦æ±‚', 'Process meets specifications')}")
                    elif cpk >= 1.0:
                        st.warning(f"âš ï¸ **{safe_text('è¿‡ç¨‹èƒ½åŠ›å°šå¯', 'Marginally Capable')}** - {safe_text('éœ€è¦æŒç»­ç›‘æ§', 'Needs monitoring')}")
                    else:
                        st.error(f"âŒ **{safe_text('è¿‡ç¨‹èƒ½åŠ›ä¸è¶³', 'Not Capable')}** - {safe_text('éœ€è¦ç«‹å³æ”¹è¿›', 'Needs improvement')}")
                
                with batch_tab4:
                    if batch_results['anomalies'] is not None and len(batch_results['anomalies']) > 0:
                        st.markdown(f"### âš ï¸ {safe_text('å‘ç°', 'Found')} {len(batch_results['anomalies'])} {safe_text('ä¸ªå¼‚å¸¸ç‚¹', 'anomalies')}")
                        
                        # æŒ‰è§„åˆ™ç»Ÿè®¡
                        rule_counts = batch_results['anomalies']['å¼‚å¸¸è§„åˆ™'].value_counts()
                        for rule, count in rule_counts.items():
                            st.warning(f"{rule}: {count}{safe_text('ä¸ªå¼‚å¸¸ç‚¹', ' anomalies')}")
                        
                        # æ˜¾ç¤ºå¼‚å¸¸ç‚¹è¡¨æ ¼
                        st.dataframe(
                            batch_results['anomalies'],
                            use_container_width=True,
                            hide_index=True
                        )
                        
                        # ä¸‹è½½æŒ‰é’®
                        csv = batch_results['anomalies'].to_csv(index=False).encode('utf-8')
                        st.download_button(
                            label=f"ğŸ“¥ {safe_text('ä¸‹è½½å¼‚å¸¸ç‚¹æ•°æ®', 'Download Anomalies')}",
                            data=csv,
                            file_name=f"anomalies_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                            mime="text/csv"
                        )
                    else:
                        st.success(f"âœ… {safe_text('æœªå‘ç°å¼‚å¸¸ç‚¹', 'No anomalies detected')}")
            
            progress_bar.progress(50)
            
            # ========== ç¬¬äºŒéƒ¨åˆ†ï¼šæ´»åŠ¨æ•°æ®åˆ†æ ==========
            status_text.text("ğŸ“‹ æ­£åœ¨åˆ†ææ´»åŠ¨æ•°æ®...")
            
            # è¯»å–æ´»åŠ¨æ•°æ®
            activity_df = pd.read_excel(activity_file)
            
            # æ‰§è¡Œæ´»åŠ¨æ•°æ®åˆ†æ
            with st.spinner("æ­£åœ¨æ‰§è¡Œæ´»åŠ¨æ•°æ®åˆ†æ..."):
                activity_results = analyze_activity_data(activity_df)
            
            if activity_results:
                st.markdown('<h2 class="sub-header">ğŸ“‹ æ´»åŠ¨æ•°æ®åˆ†æç»“æœ</h2>', unsafe_allow_html=True)
                
                # åˆ›å»ºé€‰é¡¹å¡
                activity_tab1, activity_tab2 = st.tabs(
                    [safe_text("æ•°æ®æ¸…æ´—", "Data Cleaning"), 
                     safe_text("é˜¶æ®µåˆ†æ", "Phase Analysis")]
                )
                
                with activity_tab1:
                    st.markdown(f"### {safe_text('æ•°æ®æ¸…æ´—æ­¥éª¤', 'Cleaning Steps')}")
                    for step in activity_results['cleaning_steps']:
                        st.write(f"- {step}")
                    
                    if 'batch_info' in activity_results:
                        st.markdown(f"### {safe_text('æ‰¹æ¬¡ä¿¡æ¯', 'Batch Info')}")
                        info = activity_results['batch_info']
                        st.info(
                            f"{safe_text('æ€»æ‰¹æ¬¡æ•°', 'Total Batches')}: {info['total_batches']} | "
                            f"{safe_text('æ€»è®°å½•æ•°', 'Total Records')}: {info['total_records']}"
                        )
                        if 'time_range' in info:
                            st.write(f"{safe_text('æ—¶é—´èŒƒå›´', 'Time Range')}: {info['time_range']}")
                
                with activity_tab2:
                    if activity_results['phase_analysis']:
                        # åˆ›å»ºé˜¶æ®µç»Ÿè®¡è¡¨æ ¼
                        phase_summary = []
                        for phase, analysis in activity_results['phase_analysis'].items():
                            phase_summary.append({
                                safe_text('é˜¶æ®µ', 'Phase'): phase,
                                safe_text('å¹³å‡è€—æ—¶', 'Avg'): round(analysis['å¹³å‡è€—æ—¶'], 2),
                                safe_text('æœ€å°è€—æ—¶', 'Min'): round(analysis['æœ€å°è€—æ—¶'], 2),
                                safe_text('æœ€å¤§è€—æ—¶', 'Max'): round(analysis['æœ€å¤§è€—æ—¶'], 2),
                                safe_text('æ ‡å‡†å·®', 'Std'): round(analysis['æ ‡å‡†å·®'], 2),
                                safe_text('æ´»åŠ¨æ•°', 'Activities'): analysis['æ´»åŠ¨æ•°é‡'],
                                safe_text('è®°å½•æ•°', 'Records'): analysis['è®°å½•æ•°é‡']
                            })
                        
                        if phase_summary:
                            phase_df = pd.DataFrame(phase_summary)
                            st.dataframe(phase_df, use_container_width=True, hide_index=True)
                            
                            # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
                            fig_phase, axes = plt.subplots(1, 2, figsize=(14, 5))
                            
                            # å·¦å›¾ï¼šå¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼å¯¹æ¯”
                            x = range(len(phase_df))
                            width = 0.25
                            
                            axes[0].bar([i - width for i in x], phase_df[safe_text('å¹³å‡è€—æ—¶', 'Avg')], 
                                       width, label=safe_text('å¹³å‡è€—æ—¶', 'Avg'), color='#3B82F6')
                            axes[0].bar(x, phase_df[safe_text('æœ€å°è€—æ—¶', 'Min')], 
                                       width, label=safe_text('æœ€å°è€—æ—¶', 'Min'), color='#10B981')
                            axes[0].bar([i + width for i in x], phase_df[safe_text('æœ€å¤§è€—æ—¶', 'Max')], 
                                       width, label=safe_text('æœ€å¤§è€—æ—¶', 'Max'), color='#EF4444')
                            
                            axes[0].set_xlabel(safe_text('é˜¶æ®µ', 'Phase'))
                            axes[0].set_ylabel(safe_text('æ—¶é—´ (åˆ†é’Ÿ)', 'Time (min)'))
                            axes[0].set_title(safe_text('å„é˜¶æ®µè€—æ—¶å¯¹æ¯”', 'Phase Time Comparison'))
                            axes[0].set_xticks(x)
                            axes[0].set_xticklabels(phase_df[safe_text('é˜¶æ®µ', 'Phase')], rotation=45)
                            axes[0].legend()
                            axes[0].grid(True, alpha=0.3)
                            
                            # å³å›¾ï¼šæ ‡å‡†å·®å¯¹æ¯”
                            axes[1].bar(phase_df[safe_text('é˜¶æ®µ', 'Phase')], phase_df[safe_text('æ ‡å‡†å·®', 'Std')], 
                                       color='#F59E0B')
                            axes[1].set_xlabel(safe_text('é˜¶æ®µ', 'Phase'))
                            axes[1].set_ylabel(safe_text('æ ‡å‡†å·®', 'Std Dev'))
                            axes[1].set_title(safe_text('å„é˜¶æ®µç¨³å®šæ€§å¯¹æ¯”', 'Stability Comparison'))
                            axes[1].tick_params(axis='x', rotation=45)
                            axes[1].grid(True, alpha=0.3)
                            
                            plt.tight_layout()
                            st.pyplot(fig_phase)
                        
                        # æ˜¾ç¤ºå„é˜¶æ®µè¯¦ç»†åˆ†æ
                        for phase, analysis in activity_results['phase_analysis'].items():
                            with st.expander(f"### ğŸ“Œ {phase} {safe_text('é˜¶æ®µè¯¦ç»†åˆ†æ', 'Phase Details')}"):
                                # åŸºæœ¬ç»Ÿè®¡å¡ç‰‡
                                col_p1, col_p2, col_p3, col_p4 = st.columns(4)
                                with col_p1:
                                    st.metric(safe_text("å¹³å‡è€—æ—¶", "Avg Time"), f"{analysis['å¹³å‡è€—æ—¶']:.2f}min")
                                with col_p2:
                                    st.metric(safe_text("æœ€å°è€—æ—¶", "Min Time"), f"{analysis['æœ€å°è€—æ—¶']:.2f}min")
                                with col_p3:
                                    st.metric(safe_text("æœ€å¤§è€—æ—¶", "Max Time"), f"{analysis['æœ€å¤§è€—æ—¶']:.2f}min")
                                with col_p4:
                                    st.metric(safe_text("æ ‡å‡†å·®", "Std Dev"), f"{analysis['æ ‡å‡†å·®']:.2f}")
                                
                                # æœ€å¿«å’Œæœ€æ…¢è®°å½•
                                col_record1, col_record2 = st.columns(2)
                                with col_record1:
                                    st.markdown(f"#### âš¡ {safe_text('æœ€å¿«è®°å½•', 'Fastest Record')}")
                                    if analysis['æœ€å¿«è®°å½•']:
                                        st.success(
                                            f"**{safe_text('è€—æ—¶', 'Time')}**: {analysis['æœ€å¿«è®°å½•']['æ—¶é—´']}min\n\n"
                                            f"**{safe_text('æ“ä½œå‘˜', 'Operator')}**: {analysis['æœ€å¿«è®°å½•']['æ“ä½œå‘˜']}\n\n"
                                            f"**{safe_text('æ´»åŠ¨', 'Activity')}**: {analysis['æœ€å¿«è®°å½•']['æ´»åŠ¨æè¿°']}\n\n"
                                            f"**{safe_text('æ‰¹æ¬¡', 'Batch')}**: {analysis['æœ€å¿«è®°å½•']['æ‰¹æ¬¡å·']}"
                                        )
                                    else:
                                        st.info(safe_text("æ— è®°å½•", "No data"))
                                
                                with col_record2:
                                    st.markdown(f"#### ğŸ¢ {safe_text('æœ€æ…¢è®°å½•', 'Slowest Record')}")
                                    if analysis['æœ€æ…¢è®°å½•']:
                                        st.error(
                                            f"**{safe_text('è€—æ—¶', 'Time')}**: {analysis['æœ€æ…¢è®°å½•']['æ—¶é—´']}min\n\n"
                                            f"**{safe_text('æ“ä½œå‘˜', 'Operator')}**: {analysis['æœ€æ…¢è®°å½•']['æ“ä½œå‘˜']}\n\n"
                                            f"**{safe_text('æ´»åŠ¨', 'Activity')}**: {analysis['æœ€æ…¢è®°å½•']['æ´»åŠ¨æè¿°']}\n\n"
                                            f"**{safe_text('æ‰¹æ¬¡', 'Batch')}**: {analysis['æœ€æ…¢è®°å½•']['æ‰¹æ¬¡å·']}"
                                        )
                                    else:
                                        st.info(safe_text("æ— è®°å½•", "No data"))
                                
                                if not analysis['æœ€è€—æ—¶æ´»åŠ¨'].empty:
                                    st.markdown(f"#### â±ï¸ {safe_text('è€—æ—¶æœ€é•¿çš„æ´»åŠ¨', 'Most Time-Consuming Activities')}")
                                    st.dataframe(analysis['æœ€è€—æ—¶æ´»åŠ¨'], use_container_width=True)
                                
                                if not analysis['æ•ˆç‡æœ€é«˜äººå‘˜'].empty:
                                    st.markdown(f"#### ğŸ‘¤ {safe_text('æ•ˆç‡æœ€é«˜çš„äººå‘˜', 'Most Efficient Operators')}")
                                    st.dataframe(analysis['æ•ˆç‡æœ€é«˜äººå‘˜'], use_container_width=True)
                    else:
                        st.warning(safe_text("æœªæ‰¾åˆ°é˜¶æ®µåˆ†ææ•°æ®", "No phase analysis data found"))
            
            progress_bar.progress(100)
            status_text.text("âœ… åˆ†æå®Œæˆï¼")
            
            # ========== ç»¼åˆåˆ†æç»“è®º ==========
            st.markdown("---")
            st.markdown(f'<h2 class="sub-header">{safe_text("ç»¼åˆåˆ†æç»“è®º", "Summary")}</h2>', unsafe_allow_html=True)
            
            col_sum1, col_sum2, col_sum3, col_sum4 = st.columns(4)
            
            with col_sum1:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-label">{safe_text("æ€»æ‰¹æ¬¡", "Total Batches")}</p>', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-value">{len(batch_df)}</p>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col_sum2:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-label">{safe_text("å¼‚å¸¸ç‚¹æ•°", "Anomalies")}</p>', unsafe_allow_html=True)
                anomaly_count = len(batch_results['anomalies']) if batch_results and batch_results['anomalies'] is not None else 0
                st.markdown(f'<p class="metric-value">{anomaly_count}</p>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col_sum3:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-label">{safe_text("æ€»æ´»åŠ¨æ•°", "Total Activities")}</p>', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-value">{len(activity_df)}</p>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col_sum4:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.markdown(f'<p class="metric-label">CPK</p>', unsafe_allow_html=True)
                cpk_value = batch_results['statistics']['cpk'] if batch_results else 0
                st.markdown(f'<p class="metric-value">{cpk_value:.3f}</p>', unsafe_allow_html=True)
                st.markdown('</div>', unsafe_allow_html=True)
            
            # è¿‡ç¨‹èƒ½åŠ›è¯„ä¼°
            if batch_results:
                cpk = batch_results['statistics']['cpk']
                if cpk >= 1.33:
                    st.success(f"âœ… **{safe_text('è¿‡ç¨‹èƒ½åŠ›å……è¶³', 'Capable')}** - {safe_text('è¿‡ç¨‹æ»¡è¶³è§„æ ¼è¦æ±‚', 'Process meets specifications')}")
                elif cpk >= 1.0:
                    st.warning(f"âš ï¸ **{safe_text('è¿‡ç¨‹èƒ½åŠ›å°šå¯', 'Marginally Capable')}** - {safe_text('éœ€è¦æŒç»­ç›‘æ§', 'Needs monitoring')}")
                else:
                    st.error(f"âŒ **{safe_text('è¿‡ç¨‹èƒ½åŠ›ä¸è¶³', 'Not Capable')}** - {safe_text('éœ€è¦ç«‹å³æ”¹è¿›', 'Needs improvement')}")
            
        except Exception as e:
            st.error(f"âŒ {safe_text('åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯', 'Error during analysis')}: {str(e)}")
            st.exception(e)

else:
    # æ¬¢è¿ç•Œé¢
    st.markdown(f"""
    <div style="text-align: center; padding: 3rem;">
        <h2 style="color: #1E3A8A;">{safe_text('æ¬¢è¿ä½¿ç”¨DCOç»¼åˆåˆ†æç³»ç»Ÿ', 'Welcome to DCO Analysis System')}</h2>
        <p style="color: #4B5563; font-size: 1.2rem;">{safe_text('è¯·åœ¨å·¦ä¾§æ§åˆ¶é¢æ¿ä¸Šä¼ æ•°æ®æ–‡ä»¶å¹¶å¼€å§‹åˆ†æ', 'Upload data files in the left panel to start analysis')}</p>
        <div style="margin-top: 2rem;">
            <span style="background-color: #EFF6FF; padding: 0.5rem 1rem; border-radius: 20px; margin: 0.5rem;">
                ğŸ“Š {safe_text('SPCæ§åˆ¶å›¾', 'SPC Chart')}
            </span>
            <span style="background-color: #EFF6FF; padding: 0.5rem 1rem; border-radius: 20px; margin: 0.5rem;">
                ğŸ” {safe_text('å¼‚å¸¸æ£€æµ‹', 'Anomaly Detection')}
            </span>
            <span style="background-color: #EFF6FF; padding: 0.5rem 1rem; border-radius: 20px; margin: 0.5rem;">
                ğŸ“ˆ {safe_text('å®Œæ•´ç»Ÿè®¡', 'Statistics')}
            </span>
            <span style="background-color: #EFF6FF; padding: 0.5rem 1rem; border-radius: 20px; margin: 0.5rem;">
                âš¡ {safe_text('æå€¼åˆ†æ', 'Extreme Values')}
            </span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    # ç³»ç»ŸåŠŸèƒ½è¯´æ˜
    col_func1, col_func2 = st.columns(2)
    
    with col_func1:
        st.markdown(f"""
        #### ğŸ“ˆ {safe_text('æ‰¹æ¬¡åˆ†æåŠŸèƒ½', 'Batch Analysis')}
        - {safe_text('æ•°æ®è‡ªåŠ¨æ¸…æ´—', 'Auto data cleaning')}ï¼ˆ7 {safe_text('ä¸ªæ¸…æ´—æ­¥éª¤', 'steps')}ï¼‰
        - {safe_text('SPCæ§åˆ¶å›¾ç»˜åˆ¶', 'SPC chart')}ï¼ˆ{safe_text('çº¢-é»„-ç»¿åŒºåŸŸ', 'Red-Yellow-Green zones')}ï¼‰
        - 4 {safe_text('ç§åˆ¤å¼‚è§„åˆ™æ£€æµ‹', 'control rules')}
        - {safe_text('å®Œæ•´ç»Ÿè®¡åˆ†æ', 'Complete statistics')}ï¼ˆ{safe_text('å‡å€¼ã€ä¸­ä½æ•°ã€ä¼—æ•°', 'mean, median, mode')}ï¼‰
        - {safe_text('åˆ†ä½æ•°åˆ†æ', 'Percentile analysis')}ï¼ˆ{safe_text('å‰/åååˆ†ä½ã€å‰/åå››åˆ†ä½', '10th/90th, 25th/75th')}ï¼‰
        - {safe_text('æ­£æ€åˆ†å¸ƒæ‹Ÿåˆ', 'Normal distribution fit')}
        """)
    
    with col_func2:
        st.markdown(f"""
        #### ğŸ“‹ {safe_text('æ´»åŠ¨åˆ†æåŠŸèƒ½', 'Activity Analysis')}
        - {safe_text('æ´»åŠ¨æ•°æ®è‡ªåŠ¨æ¸…æ´—', 'Auto data cleaning')}
        - 4 {safe_text('ä¸ªé˜¶æ®µåˆ†æ', 'phase analysis')}
        - {safe_text('å„é˜¶æ®µç»Ÿè®¡', 'Phase statistics')}ï¼ˆ{safe_text('å¹³å‡å€¼ã€æœ€å°å€¼ã€æœ€å¤§å€¼ã€æ ‡å‡†å·®', 'mean, min, max, std')}ï¼‰
        - {safe_text('æœ€å¿«è®°å½•å’Œæœ€æ…¢è®°å½•', 'Fastest/Slowest records')}
        - {safe_text('è€—æ—¶æœ€é•¿çš„æ´»åŠ¨æ’å', 'Most time-consuming activities')}
        - {safe_text('æ•ˆç‡æœ€é«˜çš„äººå‘˜æ’å', 'Most efficient operators')}
        """)

# ==================== é¡µè„š ====================
st.markdown("---")
st.markdown(
    f"""
    <div style="text-align: center; color: #6B7280; padding: 1rem;">
        <p>DCOç»¼åˆåˆ†æç³»ç»Ÿ v3.1 | {safe_text('ä¸­è‹±æ–‡åŒè¯­æ”¯æŒ', 'Bilingual Support')}</p>
        <p style="font-size: 0.8rem;">Â© 2024 {safe_text('ç‰ˆæƒæ‰€æœ‰', 'All Rights Reserved')}</p>
    </div>
    """,
    unsafe_allow_html=True
)
